#### Scrapy란
Scrapy는 파이썬으로 작성된 오픈 소스 웹 크롤링 프레임워크다. Scrapy를 사용하면 웹 사이트를 방문하고, 데이터를 추출하고, 원하는 형식으로 저장하는 등의 작업을 할 수 있다.

#### Scrapy의 특징
1. 강력한 크롤링 기능:Scrapy는 복잡한 웹사이트에서 데이터를 크롤링하고 추출하는데 필요한 모든 기능을 제공한다.
2. **고성능:** Scrapy는 비동기 네트워킹 라이브러리인 Twisted를 기반으로 구축되었다. 이를 통해 Scrapy는 동시에 여러 웹 페이지를 크롤링할 수 있으며, 이는 높은 성능을 보장한다.
	- Twisted는 Python에서 사용할 수 있는 이벤트 기반의 네트워킹 엔진이다.
	- 이벤트 기반 프로그래밍은 특정 이벤트가 발생할 때까지 기다리는 대신, 이벤트가 발생하면 콜백 함수를 통해 처리하는 방식을 말한다
	- 그렇기 때문에 여러 웹페이지를 동시에 크롤링할 수 있다.
3. **확장성:** Scrapy는 다양한 확장 기능을 제공한다.예를 들어, 웹 사이트 로그인, 쿠키 및 세션 관리, 사용자 에이전트 변경, 프록시 설정 등의 기능을 추가할 수 있다.
4. **유연성:** Scrapy는 웹 크롤링 작업에 대한 세밀한 제어를 가능하게 한다. 예를 들어, 크롤링의 깊이, 크롤링 속도, 다운로드 지연 등을 설정할 수 있다.
5. **편리한 데이터 처리:** Scrapy는 크롤링한 데이터를 처리하고 저장하는 방법을 자세히 지정할 수 있는 파이프라인 기능을 제공한다. 이를 통해 크롤링한 데이터를 데이터베이스에 저장하거나, 특정 형식의 파일에 저장하거나, 특정 조건에 따라 데이터를 필터링하는 등의 작업을 할 수 있다.
6. **무료 및 오픈소스:** Scrapy는 무료로 사용할 수 있으며, BSD 라이선스 하에 배포되는 오픈소스 소프트웨어다. 이는 Scrapy를 자유롭게 사용하고, 필요에 따라 수정하고, 공유할 수 있음을 의미한다.

Scrapy 프로젝트를 시작하려면 먼저 Scrapy 프레임워크를 설치해야 한다. 파이썬이 설치된 환경에서 
```python
pip install Scrapy
```
- 파이썬이 설치된 환경에서 'pip install Scrapy' 명령어를 실행하면 Scrapy를 쉽게 설치할 수 있다.

Scrapy 설치가 완료되면, Scrapy 프로젝트를 생성해야한다
```python
scrapy startproject 프로젝트이름
```
- 'scrapy startproject 프로젝트이름'을 입력한다. 
- 이렇게 하면 Scrapy 프로젝트의 기본 구조가 생성된다. 프로젝트 이름은 원하는 대로 지정하면 된다.

그런 다음 
```python
cd 프로젝트이름
```
- 'cd 프로젝트이름' 명령어로 프로젝트 폴더로 이동한다. 
- 이제 Scrapy 스파이더를 생성할 수 있다. 
- 스파이더는 특정 웹 사이트를 크롤링하고 원하는 정보를 추출하는 코드를 가지고 있다. 

스파이더를 생성하려면 
```python
scrapy genspider 스파이더이름 도메인이름
```
- 'scrapy genspider 스파이더이름 도메인이름'을 입력한다. 
- 스파이더 이름과 도메인 이름은 원하는 대로 지정하면 된다.

- Scrapy 스파이더가 생성되면, 이제 웹 사이트를 크롤링하고 데이터를 추출할 수 있다. 

스파이더를 실행하려면 
```python
scrapy crawl 스파이더이름
```
- 'scrapy crawl 스파이더이름'을 입력한다. 
- 이 명령어를 실행하면 Scrapy가 웹 사이트를 방문하고, 
- 스파이더에 작성된 코드에 따라 데이터를 추출하고, 이를 저장한다.

#### Scrapy의 다른 기능
1. Scrapy의 또 다른 강력한 기능은 파이프라인이다. 파이프라인을 사용하면, 크롤링한 데이터를 처리하고 저장하는 방법을 자세히 지정할 수 있다. 예를 들어, 크롤링한 데이터를 데이터베이스에 저장하거나, 특정 형식의 파일에 저장하거나, 특정 조건에 따라 데이터를 필터링하는 등의 작업을 할 수 있다.

2. 또한, Scrapy는 다양한 확장 기능을 제공한다. 이를 통해 Scrapy의 기능을 더욱 강화하고 사용자 정의할 수 있다. 예를 들어, 웹 사이트 로그인, 쿠키 및 세션 관리, 사용자 에이전트 변경, 프록시 설정 등의 기능을 추가할 수 있다.

Scrapy를 이용하면 복잡하고 어려운 웹 크롤링 작업을 간단하고 효율적으로 처리할 수 있다. 특히 대량의 데이터를 빠르고 안정적으로 수집해야 하는 경우, Scrapy는 뛰어난 성능을 발휘한다. 따라서 데이터 분석, 머신 러닝, 데이터 마이닝 등의 작업을 위해 웹에서 데이터를 수집해야 하는 경우, Scrapy는 매우 유용한 도구가 될 것이다.

---
#크롤링 #python #Scrapy
